ğŸ¤– AI & WhatsApp Automation Starter Kit

A production-ready Docker Compose stack that deploys a complete AI workflow engine with professional WhatsApp integration in under 10 minutes.

This repository is a strategic evolution of the n8n-io/self-hosted-ai-starter-kit, supercharged with Evolution API v2 for enterprise-grade WhatsApp automation.

âœ… What's Included
ServicePurposeVersionğŸ” n8nLow-code automation engine with 400+ integrations and advanced AI nodesLatestğŸ“± Evolution API v2Professional WhatsApp bridge (send/receive messages, media, webhooks)v2 LatestğŸ–¥ï¸ Evolution ManagerWeb UI to manage WhatsApp instances and QR code scanningLatestğŸ§  OllamaLocal LLM runner â€” runs Llama 3.2 privately, no API key neededLatestğŸ“¦ QdrantHigh-performance vector database for AI long-term memoryLatestğŸ˜ PostgreSQL (Ã—2)Separate isolated databases for n8n and Evolution API15âš¡ RedisIsolated cache layer for Evolution API session managementLatest

â­ What You Can Build

ğŸ¤ AI WhatsApp Chatbot â€” Answer customer questions 24/7 using your private LLM
ğŸ“„ PDF â†’ WhatsApp Summariser â€” Send a PDF link, get a summary back on WhatsApp
ğŸ“… Appointment Booking Bot â€” Customers book via WhatsApp, n8n writes to your calendar
ğŸ§‘â€ğŸ’¼ Lead Qualification Agent â€” Qualify inbound WhatsApp leads and route to your CRM
ğŸ“Š Internal IT Helpdesk Bot â€” Handle employee requests via a company WhatsApp number
ğŸ”” Broadcast Automation â€” Schedule and send segmented messages to contact lists


ğŸ—ºï¸ Architecture Overview
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Docker Network: workshop-net â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚   n8n :5678  â”‚â”€â”€â”€â”€â”€â–¶â”‚ evolution_api   â”‚â”€â”€â”€â”€â”€â–¶â”‚  WhatsApp (via Baileys)  â”‚  â”‚
â”‚   â”‚  (AI Engine) â”‚      â”‚ internal: :8080 â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚          â”‚                       â”‚                                              â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚  Ollama     â”‚    â”‚  evolution_redis  â”‚    â”‚  evolution_postgres        â”‚  â”‚
â”‚   â”‚  :11434     â”‚    â”‚  (internal only)  â”‚    â”‚  (internal only, :5432)    â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â”‚
â”‚   â”‚  Qdrant     â”‚    â”‚  n8n Postgres     â”‚                                     â”‚
â”‚   â”‚  :6333      â”‚    â”‚  (internal only)  â”‚                                     â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Public Ports (Firewall must allow these):
PortServiceURL5678n8nhttp://[IP]:56788081Evolution APIhttp://[IP]:80818082Evolution Manager UIhttp://[IP]:808211434Ollamahttp://[IP]:11434

ğŸš€ One-Click Setup on DigitalOcean
This is the recommended method for the workshop. Zero manual SSH required.
Step 1 â€” Create a Droplet

Log in to DigitalOcean â†’ click Create Droplet
OS: Select Ubuntu 24.04 (LTS) x64
Plan: Shared CPU â†’ Basic
CPU Option: Regular SSD or Premium Intel
Size: Select 4 GB RAM / 2 vCPUs ($24/mo)


âš ï¸ CRITICAL â€” RAM Warning: The Ollama LLM engine will crash and restart on any droplet with less than 4 GB RAM. Do not choose a smaller size. The 4 GB tier is the absolute minimum.


Datacenter Region: Choose the one closest to your physical location
Authentication: Add your SSH key or use a root password (password is fine for a workshop)

Step 2 â€” Paste the Setup Script (User Data)

Scroll down the Droplet creation page to Additional Options
Check the box: âœ… "Add Initialization scripts (User Data)"
Paste exactly the following into the text box:

bash#!/bin/bash
curl -fsSL https://raw.githubusercontent.com/EmreGunner/ai-automation-with-whatsapp-starter/main/setup.sh | bash
Step 3 â€” Launch & Wait

Click Create Droplet
â³ Wait 7â€“10 minutes. The server must:

Install Docker & dependencies
Pull all Docker images (~1.5 GB total)
Start all 7 services
Download the Llama 3.2 model via Ollama (~2 GB) â† this is the slow part


Once the Droplet shows "Active" in DigitalOcean, copy your Droplet IP Address


ğŸ’¡ Tip: You can monitor progress by SSHing in and running: tail -f /var/log/workshop-setup.log


ğŸ”— Accessing Your Tools (After Setup)
Replace [YOUR_IP] with your Droplet IP in every URL below.

1ï¸âƒ£ n8n â€” The Automation Brain
URL: http://[YOUR_IP]:5678
On your first visit, you will see an owner registration screen. This is normal â€” you are creating the admin account for this instance. Fill in an email and password, then click "Next". You will not need to verify the email.

âœ… Once registered, you land on the n8n canvas and you're ready to build workflows.


2ï¸âƒ£ Evolution Manager â€” The WhatsApp Control Panel
URL: http://[YOUR_IP]:8082
On the login screen, enter:

Server URL: http://[YOUR_IP]:8081
Global API Key: workshop-key-xyz

To connect a WhatsApp number:

Click Instances â†’ Create Instance
Give it a name (e.g., workshop)
Click Connect â€” a QR Code will appear
On your phone, open WhatsApp â†’ Settings â†’ Linked Devices â†’ Link a Device
Scan the QR code. The instance status will turn green âœ…


3ï¸âƒ£ Ollama â€” The Local AI Engine
URL: http://[YOUR_IP]:11434
If you see "Ollama is running" in your browser, the AI engine is online. The Llama 3.2 model is pre-configured and will be downloaded automatically on first start.

ğŸ”§ Internal Docker Networking â€” IMPORTANT

This is the most common source of errors for workshop participants. Please read carefully.

When building n8n workflows, you must never use the public IP address to connect services together. Instead, use the internal Docker service names. This keeps all traffic inside the private network â€” faster, cheaper, and secure.
When connecting to...âŒ Do NOT useâœ… Use this insteadEvolution APIhttp://[YOUR_IP]:8081http://evolution_api:8080Ollamahttp://[YOUR_IP]:11434http://ollama:11434Qdranthttp://[YOUR_IP]:6333http://qdrant:6333n8n Postgres[YOUR_IP]:5432postgres:5432
Why? When n8n sends a request to http://evolution_api:8080, it resolves via Docker's internal DNS â€” no packet ever leaves the server. Using the public IP routes traffic through the network interface, adding latency and exposing service ports unnecessarily.

ğŸ’» Manual Local Installation
For running this stack on your own machine (requires Docker Desktop):
bash# 1. Clone the repository
git clone https://github.com/EmreGunner/ai-automation-with-whatsapp-starter.git
cd ai-automation-with-whatsapp-starter

# 2. Copy environment config
cp env.example .env

# 3. (Optional) Edit .env to change passwords
# nano .env

# 4. Start all services
docker compose up -d

# 5. Check status
docker compose ps
Access locally:

n8n: http://localhost:5678
Evolution Manager: http://localhost:8082
Evolution API: http://localhost:8081
Ollama: http://localhost:11434

Resource note for Mac (Apple Silicon / M-series):
Docker Desktop on Mac cannot share GPU resources with containers. Ollama will run on CPU only. Expect ~2â€“3Ã— slower model inference. Everything still works â€” it's just slower.

â¬†ï¸ Upgrading
bashcd /opt/workshop
docker compose pull
docker compose up -d --remove-orphans

ğŸ” Troubleshooting
ğŸ”¥ Firewall â€” Can't access n8n or Evolution Manager?
DigitalOcean Droplets use a cloud-level firewall (separate from UFW). If your ports aren't accessible, check both layers:
Option A â€” DigitalOcean Cloud Firewall (recommended):

In DigitalOcean, go to Networking â†’ Firewalls
Create an inbound rule allowing TCP ports: 5678, 8081, 8082, 11434
Apply the firewall to your Droplet

Option B â€” UFW on the Droplet (if applicable):
bashufw allow 5678/tcp
ufw allow 8081/tcp
ufw allow 8082/tcp
ufw allow 11434/tcp
ufw reload

â„¹ï¸ By default, Ubuntu 24.04 on DigitalOcean does not have UFW enabled. Your main concern is the cloud-level firewall.


ğŸ’¾ Ollama Crashing / n8n Returning 502?
Symptom: n8n shows "502 Bad Gateway" or Ollama requests time out.
Cause: Insufficient RAM. Llama 3.2 requires ~3.5 GB of RAM to run. On a 2 GB Droplet, the container will be OOM-killed by the kernel.
Fix: Resize your Droplet to 4 GB RAM minimum (can be done in DigitalOcean without data loss â€” power off â†’ resize â†’ power on).
bash# Check memory usage on the server
free -h

# Check which containers are running
docker compose ps

# Inspect Ollama logs for OOM messages
docker compose logs ollama --tail=50

ğŸ“± Evolution API Redis Disconnected Error?
Symptom: docker logs evolution_api shows [Redis] [string] redis disconnected repeatedly.
Cause: Evolution API container started before the Redis container was fully healthy.
Fix:
bashcd /opt/workshop
docker compose restart evolution_api
# Wait 10 seconds, then check
docker compose logs evolution_api --tail=30
If it persists, do a full restart with dependency ordering:
bashdocker compose down
docker compose up -d

ğŸ˜ Evolution API "Can't reach database" Error?
Symptom: Evolution API crashes with P1001: Can't reach database server.
Cause: Evolution API started before PostgreSQL was ready to accept connections.
Fix:
bashcd /opt/workshop
# Wait for postgres to be fully ready, then restart evolution_api
docker compose restart evolution_api

ğŸ”‘ Forgot the API Key for Evolution?
The API Key is workshop-key-xyz (set in .env). You can change it by editing /opt/workshop/.env:
bashnano /opt/workshop/.env
# Edit AUTHENTICATION_API_KEY=your-new-key
docker compose up -d evolution_api  # apply change

ğŸ“œ License
This project is based on the n8n-io/self-hosted-ai-starter-kit and is licensed under the Apache License 2.0.

ğŸ’¬ Support & Community

ğŸ§µ n8n Community Forum â€” for workflow and AI node questions
ğŸ“š Evolution API Documentation â€” for WhatsApp API configuration
ğŸ“ Workshop issues? Raise a GitHub Issue on this repository
